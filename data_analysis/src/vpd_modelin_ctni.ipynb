{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(171, 4)\n",
      "(171, 4)\n",
      "(171, 4)\n",
      "(171, 4)\n",
      "(171, 4)\n",
      "(171, 4)\n",
      "(171, 4)\n",
      "(171, 4)\n",
      "(171, 4)\n",
      "(171, 2)\n",
      "(171, 38)\n"
     ]
    }
   ],
   "source": [
    "# Lendo as planilhas e também unindo as sheets\n",
    "sheet_df = pd.read_excel('/home/pves/Documentos/Workspace/heart_attack_analysis/data/Dados_para_TN_vpd.xlsx', sheet_name=None)\n",
    "dataset_list = []\n",
    "\n",
    "for key in sheet_df.keys():\n",
    "    df = sheet_df[key]\n",
    "    # Dropando as linhas do dataframe que são Nan\n",
    "    df.dropna(inplace=True, axis=0)\n",
    "    print(df.shape)\n",
    "    dataset_list.append(df)\n",
    "# Concatena todos os dataframes em um único lateralmente\n",
    "df_vpd = pd.concat(dataset_list, axis=1)\n",
    "print(df_vpd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 171 entries, 0 to 170\n",
      "Data columns (total 38 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Potencial (V)  171 non-null    float64\n",
      " 1   D              171 non-null    float64\n",
      " 2   E              171 non-null    float64\n",
      " 3   F              171 non-null    float64\n",
      " 4   Potencial (V)  171 non-null    float64\n",
      " 5   J              171 non-null    float64\n",
      " 6   K              171 non-null    float64\n",
      " 7   L              171 non-null    float64\n",
      " 8   Potencial (V)  171 non-null    float64\n",
      " 9   M              171 non-null    float64\n",
      " 10  N              171 non-null    float64\n",
      " 11  O              171 non-null    float64\n",
      " 12  Potencial (V)  171 non-null    float64\n",
      " 13  P              171 non-null    float64\n",
      " 14  Q              171 non-null    float64\n",
      " 15  R              171 non-null    float64\n",
      " 16  Potencial (V)  171 non-null    float64\n",
      " 17  S              171 non-null    float64\n",
      " 18  T              171 non-null    float64\n",
      " 19  U              171 non-null    float64\n",
      " 20  Potencial (V)  171 non-null    float64\n",
      " 21  A              171 non-null    float64\n",
      " 22  B              171 non-null    float64\n",
      " 23  C              171 non-null    float64\n",
      " 24  Potencial (V)  171 non-null    float64\n",
      " 25  G              171 non-null    float64\n",
      " 26  H              171 non-null    float64\n",
      " 27  I              171 non-null    float64\n",
      " 28  Potencial (V)  171 non-null    float64\n",
      " 29  1              171 non-null    float64\n",
      " 30  2              171 non-null    float64\n",
      " 31  3              171 non-null    float64\n",
      " 32  Potencial (V)  171 non-null    float64\n",
      " 33  1              171 non-null    float64\n",
      " 34  2              171 non-null    float64\n",
      " 35  3              171 non-null    float64\n",
      " 36  Potencial (V)  171 non-null    float64\n",
      " 37  2,88ng/mL      171 non-null    float64\n",
      "dtypes: float64(38)\n",
      "memory usage: 52.1 KB\n"
     ]
    }
   ],
   "source": [
    "# Verificando a estrutura dos dataframes e o tipo de dado que cada um possui\n",
    "df_vpd.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "concentrations_1 = {\n",
    "    'D': 20e-9,\n",
    "    'E': 20e-9,\n",
    "    'F': 20e-9,\n",
    "    'J': 10e-9,\n",
    "    'K': 10e-9,\n",
    "    'L': 10e-9,\n",
    "    'M': 4e-9,\n",
    "    'N': 4e-9,\n",
    "    'O': 4e-9,\n",
    "    'P': 2e-9,\n",
    "    'Q': 2e-9,\n",
    "    'R': 2e-9,\n",
    "    'S': 1e-9,\n",
    "    'T': 1e-9,\n",
    "    'U': 1e-9,\n",
    "    'A': 0.25e-9,\n",
    "    'B': 0.25e-9,\n",
    "    'C': 0.25e-9,\n",
    "    'G': 0.00001e-9,\n",
    "    'H': 0.00001e-9,\n",
    "    'I': 0.00001e-9,\n",
    "    '2,88ng/mL': 2.88e-9\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([22, 1])\n",
      "torch.Size([22, 1, 170])\n"
     ]
    }
   ],
   "source": [
    "target = []\n",
    "values = []\n",
    "\n",
    "for col in df_vpd.columns:\n",
    "    if col in concentrations_1.keys():\n",
    "        target.append(concentrations_1[col])\n",
    "        current_value = df_vpd.loc[1:,col].values.reshape(1,170)\n",
    "        values.append(current_value)\n",
    "\n",
    "targets = torch.from_numpy(np.array(target, dtype=np.double).reshape(-1,1))\n",
    "values_torch = torch.from_numpy(np.array(values))\n",
    "\n",
    "print(targets.shape)\n",
    "print(values_torch.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_torch = values_torch[::3]\n",
    "targets = targets[::3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1., dtype=torch.float64)\n",
      "tensor(1., dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "for tensor in range(values_torch.shape[0]):\n",
    "    #values_torch[tensor, 0,:] = (values_torch[tensor, 0,:] - values_torch[tensor, 0,:].min()) / (torch.max(values_torch[tensor, 0,:]) - values_torch[tensor, 0,:].min())\n",
    "    values_torch[tensor, 0,:] = values_torch[tensor, 0,:]  / torch.max(values_torch[tensor, 0,:])\n",
    "\n",
    "#targets = (targets - targets.min()) / (targets.max() - targets.min())\n",
    "targets = targets / targets.max()\n",
    "\n",
    "print(targets.max())\n",
    "print(values_torch.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: torch.Size([6, 1, 170])\n",
      "y_train shape: torch.Size([6, 1])\n",
      "x_test shape: torch.Size([2, 1, 170])\n",
      "y_test shape: torch.Size([2, 1])\n"
     ]
    }
   ],
   "source": [
    "# Separando em treino e teste\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(values_torch, targets, random_state=0, test_size=0.2)\n",
    "\n",
    "print(f\"x_train shape: {x_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"x_test shape: {x_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv1DModel(nn.Module):\n",
    "    def __init__(self, input_size, num_classes, input_leght):\n",
    "        super(Conv1DModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=input_size, out_channels=64, kernel_size = 3)\n",
    "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool1d(kernel_size = 2)\n",
    "        self.fc1 = nn.Linear(128 * 41, 256)  # Adjust the input size based on your data\n",
    "        self.fc2 = nn.Linear(256, 64)\n",
    "        self.fc3 = nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))        # in.shape = (1,170) out.shape = (64,168)\n",
    "        x = self.pool(x)                    # in.shape = (64, 168) out.shape = (64, 84)\n",
    "        x = self.relu(self.conv2(x))        # in.shape = (64,84) out.shape = (128,82)\n",
    "        x = self.pool(x)                    # in.shape = (128,82) out.shape = (128,41)\n",
    "        x = x.view(x.size(0), -1)           # Flatten the tensor                          \n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 1          # Assuming a 1D signal\n",
    "num_classes = 1         # For regression, num_classes should be 1\n",
    "\n",
    "model = Conv1DModel(input_size, num_classes, values_torch.shape[2])\n",
    "criterion = nn.MSELoss()                                    # Mean Squared Error loss for regression\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)        # You can choose an appropriate optimizer and learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.18290606141090393\n",
      "Epoch [2/100], Loss: 0.11374883353710175\n",
      "Epoch [3/100], Loss: 0.1030985489487648\n",
      "Epoch [4/100], Loss: 0.10860991477966309\n",
      "Epoch [5/100], Loss: 0.10351710021495819\n",
      "Epoch [6/100], Loss: 0.10632438957691193\n",
      "Epoch [7/100], Loss: 0.10334672778844833\n",
      "Epoch [8/100], Loss: 0.10524137318134308\n",
      "Epoch [9/100], Loss: 0.10283786803483963\n",
      "Epoch [10/100], Loss: 0.10463567823171616\n",
      "Epoch [11/100], Loss: 0.10308453440666199\n",
      "Epoch [12/100], Loss: 0.10330342501401901\n",
      "Epoch [13/100], Loss: 0.10355386137962341\n",
      "Epoch [14/100], Loss: 0.10251829028129578\n",
      "Epoch [15/100], Loss: 0.1030983254313469\n",
      "Epoch [16/100], Loss: 0.10265407711267471\n",
      "Epoch [17/100], Loss: 0.10236351937055588\n",
      "Epoch [18/100], Loss: 0.10271915793418884\n",
      "Epoch [19/100], Loss: 0.102147676050663\n",
      "Epoch [20/100], Loss: 0.10217954963445663\n",
      "Epoch [21/100], Loss: 0.102179616689682\n",
      "Epoch [22/100], Loss: 0.101688452064991\n",
      "Epoch [23/100], Loss: 0.10188589990139008\n",
      "Epoch [24/100], Loss: 0.1016160324215889\n",
      "Epoch [25/100], Loss: 0.10133835673332214\n",
      "Epoch [26/100], Loss: 0.10134580731391907\n",
      "Epoch [27/100], Loss: 0.10086257755756378\n",
      "Epoch [28/100], Loss: 0.1009652242064476\n",
      "Epoch [29/100], Loss: 0.10037960112094879\n",
      "Epoch [30/100], Loss: 0.1003364771604538\n",
      "Epoch [31/100], Loss: 0.09980014711618423\n",
      "Epoch [32/100], Loss: 0.09965867549180984\n",
      "Epoch [33/100], Loss: 0.09910311549901962\n",
      "Epoch [34/100], Loss: 0.09869321435689926\n",
      "Epoch [35/100], Loss: 0.09833721816539764\n",
      "Epoch [36/100], Loss: 0.09760982543230057\n",
      "Epoch [37/100], Loss: 0.09710574895143509\n",
      "Epoch [38/100], Loss: 0.09673242270946503\n",
      "Epoch [39/100], Loss: 0.09613809734582901\n",
      "Epoch [40/100], Loss: 0.09536604583263397\n",
      "Epoch [41/100], Loss: 0.09453638643026352\n",
      "Epoch [42/100], Loss: 0.09375929087400436\n",
      "Epoch [43/100], Loss: 0.09365560859441757\n",
      "Epoch [44/100], Loss: 0.09499157220125198\n",
      "Epoch [45/100], Loss: 0.09712877124547958\n",
      "Epoch [46/100], Loss: 0.09395977854728699\n",
      "Epoch [47/100], Loss: 0.08962175250053406\n",
      "Epoch [48/100], Loss: 0.09274978935718536\n",
      "Epoch [49/100], Loss: 0.09192712604999542\n",
      "Epoch [50/100], Loss: 0.08768435567617416\n",
      "Epoch [51/100], Loss: 0.09050991386175156\n",
      "Epoch [52/100], Loss: 0.0893736332654953\n",
      "Epoch [53/100], Loss: 0.08562672883272171\n",
      "Epoch [54/100], Loss: 0.08817607909440994\n",
      "Epoch [55/100], Loss: 0.08716539293527603\n",
      "Epoch [56/100], Loss: 0.08333498239517212\n",
      "Epoch [57/100], Loss: 0.085773766040802\n",
      "Epoch [58/100], Loss: 0.0863112211227417\n",
      "Epoch [59/100], Loss: 0.08160796761512756\n",
      "Epoch [60/100], Loss: 0.08065927773714066\n",
      "Epoch [61/100], Loss: 0.08320711553096771\n",
      "Epoch [62/100], Loss: 0.08411547541618347\n",
      "Epoch [63/100], Loss: 0.08037120848894119\n",
      "Epoch [64/100], Loss: 0.07674955576658249\n",
      "Epoch [65/100], Loss: 0.07789883017539978\n",
      "Epoch [66/100], Loss: 0.08061277121305466\n",
      "Epoch [67/100], Loss: 0.0798090472817421\n",
      "Epoch [68/100], Loss: 0.07567652314901352\n",
      "Epoch [69/100], Loss: 0.07281827181577682\n",
      "Epoch [70/100], Loss: 0.07340531051158905\n",
      "Epoch [71/100], Loss: 0.07605960220098495\n",
      "Epoch [72/100], Loss: 0.07799173891544342\n",
      "Epoch [73/100], Loss: 0.0771874338388443\n",
      "Epoch [74/100], Loss: 0.07197993248701096\n",
      "Epoch [75/100], Loss: 0.06881611794233322\n",
      "Epoch [76/100], Loss: 0.07056871056556702\n",
      "Epoch [77/100], Loss: 0.0730525553226471\n",
      "Epoch [78/100], Loss: 0.07237093150615692\n",
      "Epoch [79/100], Loss: 0.06763629615306854\n",
      "Epoch [80/100], Loss: 0.06643381714820862\n",
      "Epoch [81/100], Loss: 0.0688289999961853\n",
      "Epoch [82/100], Loss: 0.07224570959806442\n",
      "Epoch [83/100], Loss: 0.0725424513220787\n",
      "Epoch [84/100], Loss: 0.06707554310560226\n",
      "Epoch [85/100], Loss: 0.0641014501452446\n",
      "Epoch [86/100], Loss: 0.0664798766374588\n",
      "Epoch [87/100], Loss: 0.0684972032904625\n",
      "Epoch [88/100], Loss: 0.06671430915594101\n",
      "Epoch [89/100], Loss: 0.06289868801832199\n",
      "Epoch [90/100], Loss: 0.06332990527153015\n",
      "Epoch [91/100], Loss: 0.06544643640518188\n",
      "Epoch [92/100], Loss: 0.06455092877149582\n",
      "Epoch [93/100], Loss: 0.06250499188899994\n",
      "Epoch [94/100], Loss: 0.061165936291217804\n",
      "Epoch [95/100], Loss: 0.06093601882457733\n",
      "Epoch [96/100], Loss: 0.061546389013528824\n",
      "Epoch [97/100], Loss: 0.061477430164813995\n",
      "Epoch [98/100], Loss: 0.06047135591506958\n",
      "Epoch [99/100], Loss: 0.05958819389343262\n",
      "Epoch [100/100], Loss: 0.05924574285745621\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(values_torch.float())\n",
    "    loss = criterion(output, targets.float())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18015104017859698\n",
      "0.059303203601122886\n",
      "0.24352249095540002\n",
      "0.42152860805701553\n"
     ]
    }
   ],
   "source": [
    "from metrics_regression import Metrics_Regression\n",
    "my_metrics = Metrics_Regression(model, values_torch, targets)\n",
    "\n",
    "print(my_metrics.calc_mean_absolute_error())\n",
    "print(my_metrics.calc_mean_squared_error())\n",
    "print(my_metrics.calc_root_mean_squared_error())\n",
    "print(my_metrics.calc_r_squared())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
